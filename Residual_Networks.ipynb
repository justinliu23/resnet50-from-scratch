{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrypuuDkxRZJ"
      },
      "source": [
        "# Residual Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iILbyk8xRZN"
      },
      "source": [
        "## Table of Content\n",
        "\n",
        "- [1 - Packages](#1)\n",
        "- [2 - The Problem of Very Deep Neural Networks](#2)\n",
        "- [3 - Building a Residual Network](#3)\n",
        "    - [3.1 - The Identity Block](#3-1)\n",
        "    - [3.2 - The Convolutional Block](#3-2)\n",
        "- [4 - Building ResNet50 (50 layers)](#4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue1zR06ZxRZO"
      },
      "source": [
        "<a name='1'></a>\n",
        "## 1 - Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGDuRvIWxRZQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from resnets_utils import *\n",
        "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "\n",
        "from test_utils import summary, comparator\n",
        "import public_tests\n",
        "\n",
        "%matplotlib inline\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWEvuvpWxRZR"
      },
      "source": [
        "<a name='2'></a>\n",
        "## 2 - The Problem of Very Deep Neural Networks\n",
        "\n",
        "In recent years, neural networks have become much deeper, with state-of-the-art networks evolving from having just a few layers (e.g., AlexNet) to over a hundred layers.\n",
        "\n",
        "* The main benefit of a very deep network is that it can represent very complex functions. It can also learn features at many different levels of abstraction, from edges (at the shallower layers, closer to the input) to very complex features (at the deeper layers, closer to the output).\n",
        "\n",
        "* However, using a deeper network doesn't always help. A huge barrier to training them is vanishing gradients: very deep networks often have a gradient signal that goes to zero quickly, thus making gradient descent prohibitively slow.\n",
        "\n",
        "* More specifically, during gradient descent, as you backpropagate from the final layer back to the first layer, you are multiplying by the weight matrix on each step, and thus the gradient can decrease exponentially quickly to zero (or, in rare cases, grow exponentially quickly and \"explode,\" from gaining very large values)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCu8F7XQxRZT"
      },
      "source": [
        "<a name='3'></a>\n",
        "## 3 - Building a Residual Network\n",
        "\n",
        "In ResNets, a \"shortcut\" or a \"skip connection\" allows the model to skip layers. There is also some evidence that the ease of learning an identity function accounts for ResNets' remarkable performance even more than skip connections help with vanishing gradients.\n",
        "\n",
        "I will next implement the two main types of blocks used in a ResNet: the \"identity block\" and the \"convolutional block.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfH_xtUYxRZT"
      },
      "source": [
        "<a name='3-1'></a>\n",
        "### 3.1 - The Identity Block\n",
        "\n",
        "The identity block is the standard block used in ResNets, and corresponds to the case where the input activation (say $a^{[l]}$) has the same dimension as the output activation (say $a^{[l+2]}$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPGreUrGxRZU"
      },
      "source": [
        "These are the individual steps:\n",
        "\n",
        "First component of main path:\n",
        "- The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\". Use 0 as the seed for the random uniform initialization: `kernel_initializer = initializer(seed=0)`.\n",
        "- The first BatchNorm is normalizing the 'channels' axis.\n",
        "- Apply the ReLU activation function\n",
        "\n",
        "Second component of main path:\n",
        "- The second CONV2D has $F_2$ filters of shape $(f,f)$ and a stride of (1,1). Its padding is \"same\". Use 0 as the seed for the random uniform initialization: `kernel_initializer = initializer(seed=0)`.\n",
        "- The second BatchNorm is normalizing the 'channels' axis.\n",
        "- Then apply the ReLU activation function. This has no hyperparameters.\n",
        "\n",
        "Third component of main path:\n",
        "- The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\".\n",
        "- The third BatchNorm is normalizing the 'channels' axis.\n",
        "\n",
        "Final step:\n",
        "- The `X_shortcut` and the output from the 3rd layer `X` are added together.\n",
        "- Apply the ReLU activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-0017b68317ffa974",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "AQaWZwUgxRZU"
      },
      "outputs": [],
      "source": [
        "def identity_block(X, f, filters, initializer=random_uniform):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 4\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value for later to add back to the main path\n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X) # Default axis\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=f, strides=(1, 1), padding='same', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=1, strides=(1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "\n",
        "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjBzJN3HxRZV"
      },
      "source": [
        "<a name='3-2'></a>\n",
        "### 3.2 - The Convolutional Block\n",
        "\n",
        "The ResNet \"convolutional block\" is the second block type.\n",
        "\n",
        "* The CONV2D layer in the shortcut path is used to resize the input $x$ to a different dimension, so that the dimensions match up in the final addition needed to add the shortcut value back to the main path\n",
        "* The CONV2D layer on the shortcut path does not use any non-linear activation function. Its main role is to just apply a (learned) linear function that reduces the dimension of the input, so that the dimensions match up for the later addition step.\n",
        "\n",
        "The details of my convolutional block implementation are as follows.\n",
        "\n",
        "First component of main path:\n",
        "- The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\".\n",
        "- The first BatchNorm is normalizing the 'channels' axis.\n",
        "- Apply the ReLU activation function\n",
        "\n",
        "Second component of main path:\n",
        "- The second CONV2D has $F_2$ filters of shape (f,f) and a stride of (1,1). Its padding is \"same\".  Use 0 as the `glorot_uniform` seed `kernel_initializer = initializer(seed=0)`.\n",
        "- The second BatchNorm is normalizing the 'channels' axis.\n",
        "- Apply the ReLU activation function\n",
        "\n",
        "Third component of main path:\n",
        "- The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\".  \n",
        "- The third BatchNorm is normalizing the 'channels' axis. Note that there is no ReLU activation function in this component.\n",
        "\n",
        "Shortcut path:\n",
        "- The CONV2D has $F_3$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\".  Use 0 as the `glorot_uniform` seed `kernel_initializer = initializer(seed=0)`.\n",
        "- The BatchNorm is normalizing the 'channels' axis.\n",
        "\n",
        "Final step:\n",
        "- The shortcut and the main path values are added together.\n",
        "- Apply the ReLU activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-df47af4847e5335f",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "aNrDDUS4xRZW"
      },
      "outputs": [],
      "source": [
        "def convolutional_block(X, f, filters, s = 2, initializer=glorot_uniform):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer,\n",
        "                   also called Xavier uniform initializer.\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (m, n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "\n",
        "    # First component of main path glorot_uniform(seed=0)\n",
        "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=f, strides=(1, 1), padding='same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=1, strides=(1, 1), padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3)(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #####\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=1, strides=(s, s), padding='valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3)(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJrBUmjfxRZW"
      },
      "source": [
        "<a name='4'></a>  \n",
        "## 4 - Building ResNet50 (50 layers)\n",
        "\n",
        "We now have the necessary blocks to build a very deep ResNet.\n",
        "\n",
        "The details of this ResNet-50 model are:\n",
        "- Zero-padding pads the input with a pad of (3,3)\n",
        "- Stage 1:\n",
        "    - The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2).\n",
        "    - BatchNorm is applied to the 'channels' axis of the input.\n",
        "    - MaxPooling uses a (3,3) window and a (2,2) stride.\n",
        "- Stage 2:\n",
        "    - The convolutional block uses three sets of filters of size [64,64,256], \"f\" is 3, and \"s\" is 1.\n",
        "    - The 2 identity blocks use three sets of filters of size [64,64,256], and \"f\" is 3.\n",
        "- Stage 3:\n",
        "    - The convolutional block uses three sets of filters of size [128,128,512], \"f\" is 3 and \"s\" is 2.\n",
        "    - The 3 identity blocks use three sets of filters of size [128,128,512] and \"f\" is 3.\n",
        "- Stage 4:\n",
        "    - The convolutional block uses three sets of filters of size [256, 256, 1024], \"f\" is 3 and \"s\" is 2.\n",
        "    - The 5 identity blocks use three sets of filters of size [256, 256, 1024] and \"f\" is 3.\n",
        "- Stage 5:\n",
        "    - The convolutional block uses three sets of filters of size [512, 512, 2048], \"f\" is 3 and \"s\" is 2.\n",
        "    - The 2 identity blocks use three sets of filters of size [512, 512, 2048] and \"f\" is 3.\n",
        "- The 2D Average Pooling uses a window (pool_size) of shape (2,2).\n",
        "- The 'flatten' layer doesn't have any hyperparameters.\n",
        "- The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation.\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-10dc95a4cf6275b9",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "LHTzVwMcxRZW"
      },
      "outputs": [],
      "source": [
        "def ResNet50(input_shape = (64, 64, 3), classes = 6, training=False):\n",
        "    \"\"\"\n",
        "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "\n",
        "   ## Stage 3\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512])\n",
        "    X = identity_block(X, 3, [128, 128, 512])\n",
        "    X = identity_block(X, 3, [128, 128, 512])\n",
        "\n",
        "    ## Stage 4\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "\n",
        "    ## Stage 5\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048])\n",
        "    X = identity_block(X, 3, [512, 512, 2048])\n",
        "\n",
        "    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiFpG-ypxRZX",
        "outputId": "ae0676c2-6849-47b7-95ce-651c5c452088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 70, 70, 3)   0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 32, 32, 64)   9472        ['zero_padding2d[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 32, 32, 64)  256         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 15, 15, 64)   0           ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 15, 15, 64)   4160        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 15, 15, 64)  256         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 15, 15, 64)  256         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 15, 15, 256)  16640       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 15, 15, 256)  0           ['batch_normalization_31[0][0]', \n",
            "                                                                  'batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 15, 15, 256)  0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 15, 15, 64)   16448       ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 15, 15, 64)  256         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 15, 15, 64)  256         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 15, 15, 256)  0           ['batch_normalization_35[0][0]', \n",
            "                                                                  'activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 15, 15, 256)  0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 15, 15, 64)   16448       ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 15, 15, 64)  256         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 15, 15, 64)  256         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " conv2d_38 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 15, 15, 256)  0           ['batch_normalization_38[0][0]', \n",
            "                                                                  'activation_29[0][0]']          \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 15, 15, 256)  0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 8, 8, 128)    32896       ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 8, 8, 128)   512         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 8, 8, 128)   512         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 8, 8, 512)    131584      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 8, 8, 512)    0           ['batch_normalization_41[0][0]', \n",
            "                                                                  'batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 8, 8, 512)    0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 8, 8, 128)   512         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 8, 8, 128)   512         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 8, 8, 512)    0           ['batch_normalization_45[0][0]', \n",
            "                                                                  'activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 8, 8, 512)    0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 8, 8, 128)   512         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 8, 8, 128)   512         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 8, 8, 512)    0           ['batch_normalization_48[0][0]', \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                  'activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 8, 8, 512)    0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 8, 8, 128)   512         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 8, 8, 128)   512         ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 8, 8, 512)    0           ['batch_normalization_51[0][0]', \n",
            "                                                                  'activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 8, 8, 512)    0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 4, 4, 256)    131328      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 4, 4, 1024)   525312      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_54[0][0]', \n",
            "                                                                  'batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 4, 4, 1024)   0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_48[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_58[0][0]', \n",
            "                                                                  'activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 4, 4, 1024)   0           ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_50[0][0]']          \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " batch_normalization_59 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_61[0][0]', \n",
            "                                                                  'activation_50[0][0]']          \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 4, 4, 1024)   0           ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_53[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_64[0][0]', \n",
            "                                                                  'activation_53[0][0]']          \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 4, 4, 1024)   0           ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_58[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_67[0][0]', \n",
            "                                                                  'activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 4, 4, 1024)   0           ['add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_60[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_69[0][0]'] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_70[0][0]', \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 4, 4, 1024)   0           ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 2, 2, 512)    524800      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_63[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 2, 2, 2048)   2099200     ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 2, 2, 2048)   0           ['batch_normalization_73[0][0]', \n",
            "                                                                  'batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 2, 2, 2048)   0           ['add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 2, 2, 2048)   0           ['batch_normalization_77[0][0]', \n",
            "                                                                  'activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 2, 2, 2048)   0           ['add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_68[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " add_22 (Add)                   (None, 2, 2, 2048)   0           ['batch_normalization_80[0][0]', \n",
            "                                                                  'activation_68[0][0]']          \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 2, 2, 2048)   0           ['add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 1, 1, 2048)  0           ['activation_71[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            12294       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,600,006\n",
            "Trainable params: 23,546,886\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.set_learning_phase(True)\n",
        "\n",
        "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGiAvayWxRZX"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.00015)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "m4JpO-2cxRZY",
        "outputId": "767cb4fd-e8fc-413f-a8c4-b76f72665f73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of training examples = 1080\n",
            "number of test examples = 120\n",
            "X_train shape: (1080, 64, 64, 3)\n",
            "Y_train shape: (1080, 6)\n",
            "X_test shape: (120, 64, 64, 3)\n",
            "Y_test shape: (120, 6)\n"
          ]
        }
      ],
      "source": [
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
        "\n",
        "# Normalize image vectors\n",
        "X_train = X_train_orig / 255.\n",
        "X_test = X_test_orig / 255.\n",
        "\n",
        "# Convert training and test labels to one hot matrices\n",
        "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
        "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj-rh7uExRZY",
        "outputId": "8adc6248-aef4-42c9-8b1b-cc15e1b20daf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "34/34 [==============================] - 2s 54ms/step - loss: 0.0369 - accuracy: 0.9870\n",
            "Epoch 2/30\n",
            "34/34 [==============================] - 2s 51ms/step - loss: 0.0237 - accuracy: 0.9935\n",
            "Epoch 3/30\n",
            "34/34 [==============================] - 2s 52ms/step - loss: 0.0171 - accuracy: 0.9954\n",
            "Epoch 4/30\n",
            "34/34 [==============================] - 2s 49ms/step - loss: 0.0157 - accuracy: 0.9981\n",
            "Epoch 5/30\n",
            "34/34 [==============================] - 2s 51ms/step - loss: 0.0067 - accuracy: 0.9972\n",
            "Epoch 6/30\n",
            "34/34 [==============================] - 2s 52ms/step - loss: 0.0060 - accuracy: 0.9972\n",
            "Epoch 7/30\n",
            "34/34 [==============================] - 2s 52ms/step - loss: 0.0061 - accuracy: 0.9981\n",
            "Epoch 8/30\n",
            "34/34 [==============================] - 2s 50ms/step - loss: 0.0051 - accuracy: 0.9991\n",
            "Epoch 9/30\n",
            "34/34 [==============================] - 2s 49ms/step - loss: 0.0025 - accuracy: 0.9981\n",
            "Epoch 10/30\n",
            "34/34 [==============================] - 2s 51ms/step - loss: 0.0088 - accuracy: 0.9981\n",
            "Epoch 11/30\n",
            "34/34 [==============================] - 2s 50ms/step - loss: 0.0058 - accuracy: 0.9991\n",
            "Epoch 12/30\n",
            "34/34 [==============================] - 2s 51ms/step - loss: 0.0262 - accuracy: 0.9926\n",
            "Epoch 13/30\n",
            "34/34 [==============================] - 2s 50ms/step - loss: 0.0529 - accuracy: 0.9852\n",
            "Epoch 14/30\n",
            "34/34 [==============================] - 2s 50ms/step - loss: 0.0875 - accuracy: 0.9704\n",
            "Epoch 15/30\n",
            "34/34 [==============================] - 2s 50ms/step - loss: 0.1346 - accuracy: 0.9593\n",
            "Epoch 16/30\n",
            "34/34 [==============================] - 2s 50ms/step - loss: 0.1784 - accuracy: 0.9426\n",
            "Epoch 17/30\n",
            "34/34 [==============================] - 2s 51ms/step - loss: 0.1966 - accuracy: 0.9398\n",
            "Epoch 18/30\n",
            "34/34 [==============================] - 2s 51ms/step - loss: 0.0818 - accuracy: 0.9685\n",
            "Epoch 19/30\n",
            "34/34 [==============================] - 2s 51ms/step - loss: 0.0520 - accuracy: 0.9852\n",
            "Epoch 20/30\n",
            "34/34 [==============================] - 2s 52ms/step - loss: 0.0534 - accuracy: 0.9861\n",
            "Epoch 21/30\n",
            "34/34 [==============================] - 2s 50ms/step - loss: 0.0233 - accuracy: 0.9917\n",
            "Epoch 22/30\n",
            "34/34 [==============================] - 2s 50ms/step - loss: 0.0177 - accuracy: 0.9935\n",
            "Epoch 23/30\n",
            "34/34 [==============================] - 2s 51ms/step - loss: 0.0205 - accuracy: 0.9935\n",
            "Epoch 24/30\n",
            "34/34 [==============================] - 2s 50ms/step - loss: 0.0133 - accuracy: 0.9944\n",
            "Epoch 25/30\n",
            "34/34 [==============================] - 2s 51ms/step - loss: 0.0174 - accuracy: 0.9944\n",
            "Epoch 26/30\n",
            "34/34 [==============================] - 2s 50ms/step - loss: 0.0082 - accuracy: 0.9981\n",
            "Epoch 27/30\n",
            "34/34 [==============================] - 2s 51ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "34/34 [==============================] - 2s 51ms/step - loss: 6.5642e-04 - accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "34/34 [==============================] - 2s 51ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "34/34 [==============================] - 2s 50ms/step - loss: 3.5746e-04 - accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fec64d15460>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, Y_train, epochs = 30, batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "bzOmeS4sxRZZ",
        "outputId": "9e04ba18-c160-415a-93f7-97a0742dff28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2779 - accuracy: 0.9417\n",
            "Loss = 0.2778650224208832\n",
            "Test Accuracy = 0.9416666626930237\n"
          ]
        }
      ],
      "source": [
        "preds = model.evaluate(X_test, Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF-ErVoRxRZZ"
      },
      "outputs": [],
      "source": [
        "pre_trained_model = load_model('resnet50.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkMq9d7sxRZZ",
        "outputId": "0a8a4df3-b7e3-444a-d4d9-7eacc6faf902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 8ms/step - loss: 0.1596 - accuracy: 0.9500\n",
            "Loss = 0.1595880389213562\n",
            "Test Accuracy = 0.949999988079071\n"
          ]
        }
      ],
      "source": [
        "preds = pre_trained_model.evaluate(X_test, Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}